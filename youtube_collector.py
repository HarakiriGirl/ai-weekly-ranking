#!/usr/bin/env python3
"""
YouTubeé€±æ¬¡åé›†ã‚·ã‚¹ãƒ†ãƒ 
æ¯é€±æŒ‡å®šãƒãƒ£ãƒ³ãƒãƒ«ã®æ–°ç€å‹•ç”»ã‚’åé›†
"""

import requests
import json
import csv
import os
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Tuple
from pathlib import Path
import time

def load_channel_list(csv_file: str) -> List[Tuple[str, str, str]]:
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ã‚’èª­ã¿è¾¼ã¿
    æˆ»ã‚Šå€¤: [(channel_id, name, handle), ...]
    """
    channels = []
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row.get('status') == 'æˆåŠŸ':  # æˆåŠŸã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®ã¿å‡¦ç†
                    channels.append((
                        row['channel_id'].strip(),
                        row['name'].strip(),
                        row['handle'].strip()
                    ))
        print(f"ğŸ“‹ {len(channels)}ãƒãƒ£ãƒ³ãƒãƒ«ã‚’CSVã‹ã‚‰èª­ã¿è¾¼ã¿")
        return channels
    except Exception as e:
        print(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def fetch_weekly_videos(api_key: str, channel_id: str, channel_name: str) -> Dict:
    """
    æŒ‡å®šãƒãƒ£ãƒ³ãƒãƒ«ã®éå»7æ—¥é–“ã®å‹•ç”»ã‚’å–å¾—
    """
    print(f"ğŸ” å‹•ç”»å–å¾—é–‹å§‹: {channel_name}")
    
    # 7æ—¥å‰ã®æ—¥ä»˜ã‚’è¨ˆç®—ï¼ˆUTCï¼‰
    week_ago = datetime.now(timezone.utc) - timedelta(days=7)
    published_after = week_ago.isoformat()
    
    url = "https://www.googleapis.com/youtube/v3/search"
    params = {
        'part': 'snippet',
        'channelId': channel_id,
        'type': 'video',
        'order': 'date',
        'publishedAfter': published_after,
        'maxResults': 50,
        'key': api_key
    }
    
    try:
        response = requests.get(url, params=params, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        # ã‚¨ãƒ©ãƒ¼å¿œç­”ãƒã‚§ãƒƒã‚¯
        if 'error' in data:
            print(f"  âŒ API ã‚¨ãƒ©ãƒ¼: {data['error']['message']}")
            return {
                "channel_id": channel_id,
                "videos": [],
                "status": "api_error",
                "error": data['error']['message']
            }
        
        videos = []
        for item in data.get('items', []):
            video = {
                'title': item['snippet']['title'],
                'tags': item['snippet'].get('tags', []),  # ã‚¿ã‚°é…åˆ—ï¼ˆãªã‘ã‚Œã°ç©ºé…åˆ—ï¼‰
                'published_at': item['snippet']['publishedAt']
            }
            videos.append(video)
        
        print(f"  âœ… {len(videos)}æœ¬ã®å‹•ç”»ã‚’å–å¾—")
        return {
            "channel_id": channel_id,
            "videos": videos,
            "status": "success"
        }
        
    except requests.exceptions.Timeout:
        print(f"  âŒ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
        return {"channel_id": channel_id, "videos": [], "status": "timeout"}
    except requests.exceptions.RequestException as e:
        print(f"  âŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        return {"channel_id": channel_id, "videos": [], "status": "network_error", "error": str(e)}
    except Exception as e:
        print(f"  âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return {"channel_id": channel_id, "videos": [], "status": "unexpected_error", "error": str(e)}

def get_jst_timestamp() -> str:
    """æ—¥æœ¬æ™‚é–“ã§ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç”Ÿæˆï¼ˆpytzä¸ä½¿ç”¨ï¼‰"""
    jst_offset = timezone(timedelta(hours=9))
    now_jst = datetime.now(jst_offset)
    return now_jst.strftime('%Y%m%d_%H%M%S')

def process_youtube_channels(api_key: str, csv_file: str):
    """YouTubeãƒãƒ£ãƒ³ãƒãƒ«ã‚’å‡¦ç†ã—ã¦JSONã«ä¿å­˜"""
    today = datetime.now().strftime('%Y-%m-%d')
    
    result = {
        "collection_date": today,
        "collection_date_jst": datetime.now(timezone(timedelta(hours=9))).isoformat(),
        "source": "YouTube Data API v3",
        "total_channels": 0,
        "successful_channels": 0,
        "failed_channels": 0,
        "total_videos": 0,
        "channels": {}
    }
    
    print(f"ğŸ¥ YouTubeé€±æ¬¡åé›†é–‹å§‹: {today}")
    print("-" * 50)
    
    # ãƒãƒ£ãƒ³ãƒãƒ«ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿
    channels = load_channel_list(csv_file)
    if not channels:
        print("âŒ å‡¦ç†å¯¾è±¡ã®ãƒãƒ£ãƒ³ãƒãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        return result
    
    result["total_channels"] = len(channels)
    
    # å„ãƒãƒ£ãƒ³ãƒãƒ«ã‚’å‡¦ç†
    for i, (channel_id, channel_name, handle) in enumerate(channels, 1):
        print(f"\nğŸ“º ãƒãƒ£ãƒ³ãƒãƒ« {i}/{len(channels)}: {channel_name} (@{handle})")
        
        # é€±é–“å‹•ç”»ã‚’å–å¾—
        channel_data = fetch_weekly_videos(api_key, channel_id, channel_name)
        
        if channel_data["status"] == "success":
            result["successful_channels"] += 1
            result["total_videos"] += len(channel_data["videos"])
        else:
            result["failed_channels"] += 1
        
        # ãƒãƒ£ãƒ³ãƒãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        result["channels"][channel_name] = {
            "channel_id": channel_id,
            "handle": handle,
            "video_count": len(channel_data["videos"]),
            "videos": channel_data["videos"],
            "collection_status": channel_data["status"]
        }
        
        if channel_data["status"] != "success":
            result["channels"][channel_name]["error"] = channel_data.get("error", "")
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼ˆ1ç§’å¾…æ©Ÿï¼‰
        if i < len(channels):
            time.sleep(1)
    
    # çµ±è¨ˆæƒ…å ±
    result["summary"] = {
        "total_channels": result["total_channels"],
        "successful_channels": result["successful_channels"],
        "failed_channels": result["failed_channels"],
        "total_videos": result["total_videos"],
        "success_rate": f"{(result['successful_channels'] / result['total_channels'] * 100):.1f}%" if result["total_channels"] > 0 else "0%"
    }
    
    print("-" * 50)
    print(f"ğŸ“Š å‡¦ç†å®Œäº†:")
    print(f"  ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {result['total_channels']}å€‹")
    print(f"  æˆåŠŸ: {result['successful_channels']}å€‹")
    print(f"  å¤±æ•—: {result['failed_channels']}å€‹")
    print(f"  ç·å‹•ç”»æ•°: {result['total_videos']:,}æœ¬")
    print(f"  æˆåŠŸç‡: {result['summary']['success_rate']}")
    
    return result

def save_youtube_data(data):
    """YouTubeã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
    # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    data_dir = Path("data/youtube/weekly")
    data_dir.mkdir(parents=True, exist_ok=True)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆï¼ˆJSTæ™‚åˆ»ï¼‰
    jst_timestamp = get_jst_timestamp()
    filename = data_dir / f"youtube_weekly_{jst_timestamp}.json"
    
    # JSONä¿å­˜
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {filename}")
    return str(filename)

def test_single_channel():
    """ãƒ†ã‚¹ãƒˆç”¨: 1ãƒãƒ£ãƒ³ãƒãƒ«ã®ã¿åé›†"""
    api_key = os.environ.get('YOUTUBE_API_KEY')
    if not api_key:
        print("âŒ YOUTUBE_API_KEY ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒãƒ£ãƒ³ãƒãƒ«ï¼ˆã‚¦ã‚§ãƒ–è·TVï¼‰
    test_channel_id = "UClNZUVnSFRKKUfJYarEUqdA"
    test_channel_name = "ã‚¦ã‚§ãƒ–è·TV"
    
    print(f"ğŸ§ª ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ: {test_channel_name}")
    
    result = fetch_weekly_videos(api_key, test_channel_id, test_channel_name)
    
    print(f"\nğŸ“Š ãƒ†ã‚¹ãƒˆçµæœ:")
    print(f"  ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {result['status']}")
    print(f"  å‹•ç”»æ•°: {len(result['videos'])}æœ¬")
    
    if result['videos']:
        print(f"\nğŸ“„ æœ€æ–°å‹•ç”»:")
        latest_video = result['videos'][0]
        print(f"  ã‚¿ã‚¤ãƒˆãƒ«: {latest_video['title']}")
        print(f"  ã‚¿ã‚°: {latest_video['tags']}")
        print(f"  å…¬é–‹æ—¥: {latest_video['published_at']}")
    
    return result

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        import sys
        
        # APIã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯
        api_key = os.environ.get('YOUTUBE_API_KEY')
        if not api_key:
            print("âŒ ã‚¨ãƒ©ãƒ¼: YOUTUBE_API_KEY ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            print("ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œã®å ´åˆ:")
            print("  Windows: set YOUTUBE_API_KEY=ã‚ãªãŸã®APIã‚­ãƒ¼")
            print("  Mac/Linux: export YOUTUBE_API_KEY=ã‚ãªãŸã®APIã‚­ãƒ¼")
            return
        
        # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰
        if len(sys.argv) > 1 and sys.argv[1] == "test":
            print("ğŸ§ª ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œ")
            test_single_channel()
            return
        
        # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰
        csv_file = 'youtube_channel_ids.csv'
        if not os.path.exists(csv_file):
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {csv_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        print("ğŸ¥ YouTubeåé›†ãƒ¢ãƒ¼ãƒ‰")
        data = process_youtube_channels(api_key, csv_file)
        save_youtube_data(data)
        
        print("âœ… å‡¦ç†å®Œäº†")
        
    except Exception as e:
        print(f"ğŸ’¥ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}")
        exit(1)

if __name__ == "__main__":
    main()